{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITMAL Exercise\n",
    "\n",
    "\n",
    "REVISIONS||\n",
    "---------||\n",
    "2018-1219| CEF, initial.                  \n",
    "2018-0207| CEF, updated.           \n",
    "2018-0207| CEF, rewritten accuracy paradox section. \n",
    "2018-0305| CEF, updated with SHN comments.\n",
    "2019-0901| CEF, updated for ITMAL v2.\n",
    "2019-0904| CEF, updated for print-f and added conclusion Q.\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "There are a number of frequently uses metrics in ML, namely accuracy, precision, recall and the $F_1$ score. All are called _metrics_ (though they are not true norms, like ${\\cal L}_2$ or ${\\cal L}_1$ we saw last time).\n",
    "\n",
    "Maybe performance _score_ would be a better name than performance metric, at least for the accuracy, precision, recall we will be looking at---emphasising the conceptual distinction between the  _score-function_ and _cost(/loss/error/objective)-function_ (the later is typically a true distance/norm function).  \n",
    "\n",
    "You can find a lot of details on say precision and recall in Wikipedia\n",
    "\n",
    ">  https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "\n",
    "### Nomenclature\n",
    "\n",
    "| NAME | SYMBOL | ALIAS |\n",
    "| :---: | :---: | :---: |\n",
    "|true positives | $TP$ | |\n",
    "|true negatives | $TN$ | |\n",
    "|false positives| $FP$ | type I error| \n",
    "|false negatives| $FN$ | type II error |\n",
    "\n",
    "and $N = N_P + N_N$ being the total number of samples and the number of positive and negative samples\n",
    "respectively.\n",
    "\n",
    "### Precision\n",
    "\n",
    "$$\n",
    "\\def\\by{\\mathbf{y}}\n",
    "\\def\\ba{\\begin{array}{lll}}\n",
    "\\def\\ea{\\end{array}}\n",
    "\\newcommand{\\rem}[1]{}\n",
    "\\newcommand\\st[1]{_{\\scriptsize #1}}\n",
    "\\newcommand\\myfrac[2]{\\frac{#1\\rule{0pt}{8pt}}{#2\\rule{0pt}{8pt}}} \n",
    "\\ba\n",
    " p &= \\myfrac{TP}{TP + FP}\n",
    "\\ea\n",
    "$$\n",
    "\n",
    "### Recall or Sensitivity\n",
    "\n",
    "$$\n",
    "  \\ba\n",
    "    r &= \\myfrac{TP}{TP + FN}\\\\\n",
    "      &= \\myfrac{TP}{N_P}\n",
    "  \\ea\n",
    "$$\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "$$\n",
    "  \\ba\n",
    "      a &= \\myfrac{TP + TN}{TP + TN + FP + FN}\\\\\n",
    "        &= \\myfrac{TP + TN}{N}\\\\\n",
    "        &= \\myfrac{TP + TN}{N_P~~ + N_N} \n",
    "  \\ea\n",
    "$$\n",
    "\n",
    "#### Accuracy Paradox\n",
    "\n",
    "A static constant model, say $p\\st{cancer}=0$ may have higher accuracy than a real model with predictive power. This is odd!\n",
    "\n",
    "Asymmetric weight could also be associated with the false positive and false negative predictions, yielding either FP of FN much more expensive than the other. Say, it is more expensive not to treat a person with cancer, than treating a person without cancer. \n",
    "\n",
    "### F-score\n",
    "\n",
    "General $\\beta$-harmonic mean of the precision and recall \n",
    "$$\n",
    "    F_\\beta = (1+\\beta^2) \\myfrac{2pr}{\\beta^2 p+r}\\\\\n",
    "$$ \n",
    "that for say $\\beta=2$ or $\\beta=0.5$ shifts or skews the emphasis on the two variables in the equation. Normally only the $\\beta=1$ harmonic mean is used\n",
    "\n",
    "$$\n",
    "  \\ba\n",
    "    F_1 &= \\myfrac{2pr}{p+r}\\\\\n",
    "        &= \\myfrac{2}{1/p + 1/r}\n",
    "  \\ea\n",
    "$$\n",
    "with $F$ typically being synonymous with $F_1$. \n",
    "\n",
    "If needed, find more info on Wikipedia\n",
    "\n",
    "> https://en.wikipedia.org/wiki/F1_score\n",
    "\n",
    "\n",
    "## Confusion Matrix\n",
    "\n",
    "For statistical classification, the confusion matrix or error matrix (or\n",
    "matching matrix in unsupervised learning) is for a two-class problem given by\n",
    "the $2\\times2$ matrix with dimensions 'actual' and 'predicted'\n",
    "\n",
    "$$   \n",
    "{\\bf M}\\st{confusion} = \n",
    "\\begin{array}{l|ll}\n",
    "                           & \\mbox{actual true} & \\mbox{actual false} \\\\ \\hline\n",
    "    \\mbox{predicted true}  & TP & FP \\\\     \n",
    "    \\mbox{predicted false} & FN & TN \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The diagonal, in the square matrix, represent predicted values being the same\n",
    "as the actual values, off-diagonal elements represent erroneous prediction.\n",
    "\n",
    "Also notice, that the layout of this matrix is different of what is given in [HOML], \"Confusion Matrix\", p.86/fig 3-2. This is just a minor issue, since we can always flip/rotate/transpose the matrix (say by flipping the $\\by\\st{true}$ and $\\by\\st{pred}$ arguments). \n",
    "\n",
    "For N-class classification the matrix gives a matrix with $N$ actual\n",
    "classes and $N$ predicted classes\n",
    "\n",
    "$$\n",
    "{\\bf M}\\st{confusion}~~~ =\n",
    "  \\left[\n",
    "  \\begin{array}{llll}\n",
    "       c_{11} & c_{12} & \\cdots & c_{1n} \\\\ \n",
    "       c_{21} & c_{22} & \\cdots & c_{2n} \\\\\n",
    "       \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "       c_{n1} & c_{n2} & \\cdots & c_{nn} \\\\ \n",
    "  \\end{array}\n",
    "  \\right]\n",
    "$$\n",
    "with say element $c_{21}$ being the number of actual classes '1' being predicted (erroneously) as class '2'.\n",
    "\n",
    "### Nomenclature for the Confusion Matrix\n",
    "\n",
    "The naming of the elements in the confusion matrix can be rather exotic, like _false omission rate_ (see the figure below), but we won't get to such detail here...let us stick with TP, TN, FP, FN and $F_1$!\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/E19_itmal/L02/Figs/performance_metrics.png\" style=\"width:900px\">\n",
    "\n",
    "If you need more info on the confusion matrix:\n",
    "\n",
    ">  https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "#### Qa Implement the Accuracy function and test it on the MNIST data.\n",
    "\n",
    "We now follow the convention in Scikit-learn, that a score funtion takes the arguments `y_true` and then `y_pred`\n",
    "\n",
    "```\n",
    "    sklearn.metrics.accuracy_score(y_true, y_pred, ..)\n",
    "```\n",
    "\n",
    "Implement a general accuracy function `MyAccuracy(y_true, y_pred)`.\n",
    "\n",
    "Reuse your MNIST data loader and test the `MyAccuracy` function  both on your dummy classifier and on the Stochastic Gradient Descent classifier (with setup parameters as in [HOLM]).\n",
    "\n",
    "Compare your accuracy score with the acutal value from `sklearn.metrics.accuracy_score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for X_test[15]:  [False]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from IPython.display import Math, display, Latex\n",
    "\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784',return_X_y=True)\n",
    "X = X / 255.\n",
    "\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "#Creating the training and test datasets.\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n",
    "#Shuffle dataset\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "\n",
    "#Creating the binary classifier for 5!\n",
    "y_train_5 = (y_train == '5')    \n",
    "y_test_5  = (y_test == '5')\n",
    "\n",
    "#Create SGD\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "sgd_pred5 = sgd_clf.predict(X_test)\n",
    "\n",
    "#Create Dummy Classifier\n",
    "class DummyClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "#Fit dataset\n",
    "dum_clf = DummyClassifier()\n",
    "dum_clf.fit(X_train, y_train_5)\n",
    "\n",
    "#Predict and print a 5\n",
    "dum_pred5 = dum_clf.predict(X_test)\n",
    "print('Prediction for X_test[15]: ',dum_pred5[15])\n",
    "MNIST_PlotDigit(X_test[15])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my a\t\t=0.9108\n",
      "scikit-learn a\t=0.9108\n",
      "We have the same accuracy! Hallelujah!\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "def getSamples(y_true, y_pred):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    n = y_true.shape[0]\n",
    "    assert y_true.shape[0] == y_pred.shape[0]    \n",
    "    for i in range(n):\n",
    "        if y_true[i] == True and y_pred[i] == True:\n",
    "            TP = TP + 1\n",
    "        elif y_true[i] == True and y_pred[i] == False:\n",
    "            FN = FN + 1\n",
    "        elif y_true[i] == False and y_pred[i] == False:\n",
    "            TN = TN + 1\n",
    "        else:\n",
    "            FP = FP + 1\n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def MyAccuracy(y_true, y_pred):\n",
    "    TP, TN, FP, FN = getSamples(y_true, y_pred)\n",
    "    cg = TP+TN\n",
    "    N = TP+TN+FP+FN\n",
    "    Accuracy = cg/N\n",
    "    return Accuracy\n",
    "    \n",
    "# TEST FUNCTION: example of a comperator, using Scikit-learn accuracy_score\n",
    "def TestAccuracy(y_true, y_pred):\n",
    "    a0=MyAccuracy(y_true, y_pred)\n",
    "    a1=accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nmy a\\t\\t={a0}\")\n",
    "    print(f\"scikit-learn a\\t={a1}\")\n",
    "    if math.fabs(a0-a1)==0:\n",
    "        print('We have the same accuracy! Hallelujah!')\n",
    "\n",
    "\n",
    "TestAccuracy(y_test_5,dum_pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb Implement Precision, Recall and $F_1$-score and test it on the MNIST data.\n",
    "\n",
    "Now, implement the `MyPrecision`, `MyRecall` and `MyF1Score` functions, again taking MNIST as input, using the SGD and the Dummy classifiers and make some test vectors to compare to the functions found in Scikit-learn..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: TP was 0\n",
      "P: TP + FP is 0\n",
      "F: p+r was 0\n",
      "F1 Score for dummy was: 0\n",
      "F1 Score for SGD was: 0.8501362397820164\n"
     ]
    }
   ],
   "source": [
    "def MyPrecision(y_true, y_pred):\n",
    "    TP, TN, FP, FN = getSamples(y_true, y_pred)\n",
    "    cg = TP+TN\n",
    "    other = TP+FP\n",
    "    if other == 0:\n",
    "        print('P: TP + FP is 0')\n",
    "        return 0\n",
    "    Precision = TP/other\n",
    "    if Precision == 0:\n",
    "        print('P: TP was 0')\n",
    "    return Precision\n",
    "\n",
    "def MyRecall(y_true, y_pred):\n",
    "    TP, TN, FP, FN = getSamples(y_true, y_pred)\n",
    "    np = TP+FN\n",
    "    if np == 0:\n",
    "        print('R: TP+FN was 0')\n",
    "        return 0\n",
    "    Recall = TP/np\n",
    "    if Recall == 0:\n",
    "        print('R: TP was 0')\n",
    "    return Recall\n",
    "    \n",
    "def MyF1Score(y_true, y_pred):\n",
    "    r = MyRecall(y_true,y_pred)\n",
    "    p = MyPrecision(y_true, y_pred)\n",
    "    t = 2*p*r\n",
    "    b = p+r\n",
    "    if b == 0:\n",
    "        print('F: p+r was 0')\n",
    "        return 0\n",
    "    return t/b\n",
    "    \n",
    "print('F1 Score for dummy was:', MyF1Score(y_test_5,dum_pred5))\n",
    "print('F1 Score for SGD was:', MyF1Score(y_test_5,sgd_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qc The Confusion Matrix\n",
    "\n",
    "Revisit your solution to Qb in the `dummy_classifier.ipynb`. Generate the confusion matrix for both the Dummy and the SGD classifier using the `scklearn.metrics.confusion_matrix` function. \n",
    "\n",
    "I got the two confusion matrices\n",
    "$$\n",
    "M_{dummy} = \\begin{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        18166 & 0\n",
    "    \\end{bmatrix} \\newline    \n",
    "    \\begin{bmatrix}\n",
    "        1834 & 0\n",
    "    \\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And\n",
    "\n",
    "$$\n",
    "M_{SDG} = \\begin{bmatrix}\n",
    "    \\begin{bmatrix}\n",
    "        17618 & 548\n",
    "    \\end{bmatrix} \\newline    \n",
    "    \\begin{bmatrix}\n",
    "        267 & 1567 \n",
    "    \\end{bmatrix}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "your data may look similar (but not 100% equal).\n",
    "\n",
    "How are the Scikit-learn confusion matrix organized, where are the TP, FP, FN and TN located in the matrix indices, and what happens if you mess up the parameters calling\n",
    "\n",
    "```python\n",
    "confusion_matrix(y_train_pred, y_train_5)\n",
    "```\n",
    "\n",
    "instead of \n",
    "```python\n",
    "confusion_matrix(y_train_5, y_train_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for dummy: \n",
      " [[9108    0]\n",
      " [ 892    0]]\n",
      "Confusion Matrix for SGD: \n",
      " [[9065   43]\n",
      " [ 188  704]]\n"
     ]
    }
   ],
   "source": [
    "#Matrix conversion tool\n",
    "def bmatrix(a):\n",
    "    \"\"\"Returns a LaTeX bmatrix\n",
    "\n",
    "    :a: numpy array\n",
    "    :returns: LaTeX bmatrix as a string\n",
    "    \"\"\"\n",
    "    if len(a.shape) > 2:\n",
    "        raise ValueError('bmatrix can at most display two dimensions')\n",
    "    lines = str(a).replace('[', '').replace(']', '').splitlines()\n",
    "    rv = [r'\\begin{bmatrix}']\n",
    "    rv += ['  ' + ' & '.join(l.split()) + r'\\\\' for l in lines]\n",
    "    rv +=  [r'\\end{bmatrix}']\n",
    "    return '\\n'.join(rv)\n",
    "\n",
    "#Create confusion matix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "M_dummy = confusion_matrix(y_test_5,dum_pred5)\n",
    "M_SGD = confusion_matrix(y_test_5,sgd_pred5)\n",
    "\n",
    "print('Confusion Matrix for dummy: \\n', M_dummy)\n",
    "print('Confusion Matrix for SGD: \\n', M_SGD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for dummy: \n",
      " [[9108  892]\n",
      " [   0    0]]\n",
      "Confusion Matrix for SGD: \n",
      " [[9065  188]\n",
      " [  43  704]]\n"
     ]
    }
   ],
   "source": [
    "#Create fake confusion matrix\n",
    "print('Confusion Matrix for dummy: \\n',confusion_matrix(dum_pred5, y_test_5))\n",
    "print('Confusion Matrix for SGD: \\n',confusion_matrix(sgd_pred5, y_test_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man ved at matrixen er bygget således op: \n",
    "[[TN, FP]\n",
    " [FN, TP]]\n",
    " \n",
    "Men når man bytter disse rundt, så får man: \n",
    "[[TN, FN]\n",
    " [FP, TP]]\n",
    " \n",
    "Derfor vil dette godt kunne skabe forvirring, hvis man byttede rundt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qd A Confusion Matrix Heat-map\n",
    "\n",
    "Generate a _heat map_ image for the confusion matrices, `M_dummy` and `M_SGD` respectively, getting inspiration from [HOML] \"Error Analysis\", pp.96-97.\n",
    "\n",
    "This heat map could be an important guide for you when analysing multiclass data in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SKAL VI HAVE DENNE HER???\n",
    "#TODO: TJEK!\n",
    "\n",
    "#Lav cross val for sgd_clf\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_train_pred_sgd = cross_val_predict(sgd_clf, X_train,y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred_sgd)\n",
    "\n",
    "#Compare error rates instead of absolute number of errors\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "#Fill diagonals with zeros to keep only the errors\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,10) (2,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-c5af6cf98860>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Compare error rates instead of absolute number of errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrow_sums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM_dummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnorm_conf_mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconf_mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrow_sums\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Fill diagonals with zeros to keep only the errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,10) (2,1) "
     ]
    }
   ],
   "source": [
    "#M_dummy\n",
    "#Compare error rates instead of absolute number of errors\n",
    "row_sums = M_dummy.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "#Fill diagonals with zeros to keep only the errors\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M_dummy\n",
    "#Compare error rates instead of absolute number of errors\n",
    "row_sums = M_SGD.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "#Fill diagonals with zeros to keep only the errors\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qe Conclusion\n",
    "\n",
    "Now, conclude on all the exercise above. \n",
    "\n",
    "Write a short textual conclusion (max. 10- to 20-lines) that extract the _essence_ of the exercises: why did you think it was important to look at these particular ML concepts, and what was our overall learning outcome of the exercises (in broad terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der er mange forskellige måder, at en Classifier kan vise sig at være \"dårlig\" på - men der er også tilfælde, hvor en Classifier kan have en OK succes rate, men reelt set være \"dårlig\". \n",
    "Confusion Matrix, Precision, Accuray og Recall kan her være med til at informere om, hvorhenne at en Classifier er dårlig. \n",
    "Confusion matrixen er god til at se mængden af Falske Positiver osv. Denne hjalp fx rigtig meget, da man lavede Dummy Classifier, da man her kan se, at den kun svarer de negative værdier og dermed aldig gætter, at noget er true. Dog så man i \"Dummy_Classifier\", at den alligevel gætter rigtig i 90% af tiden - fordi 5'erne kun fylder med 10%. \n",
    "De andre Precision, Accuracy og Recall kan her også være gode midler til at hjælpe med at spotte netop det område, hvor ens Classifier ikke nødvendigvis er helt så god. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
